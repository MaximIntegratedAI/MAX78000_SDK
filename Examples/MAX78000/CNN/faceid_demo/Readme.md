# MAX78000 FaceID Demo



## Overview
The FaceID Demo software demonstrates identification of a number of persons from their facial images using MAX78000 EVKIT.

For this purpose, the CNN model generates a 512-length embedding for a given image, whose distance to whole embeddings stored for each subject is calculated. The image is identified as either one of these subjects or 'Unknown' depending on the embedding distances.

The CNN model is trained with the VGGFace-2 dataset using MTCNN and FaceNet models for embedding generation.

The code is auto-generated by the ai8x-synthesis tool and runs a known-answer test with a pre-defined input sample.

## FaceID Demo Software

### Building firmware:

Navigate directory where FaceID demo software is located and build the project:

```bash
$ cd /Examples/MAX78000/CNN/faceid_demo
$ make
```

If this is the first time after installing tools, or peripheral files have been updated, first clean drivers before rebuilding the project: 

```bash
$ make distclean
```

### Load firmware image to target:

Connect USB cable to CN1 (USB/PWR) and turn ON power switch (SW1). Note the COM port (COM_PORT) of this connection from your system configuration.

Connect PICO adapter to JH5 SWD header. 

Load firmware image using Openocd. **Make sure to remove PICO adapter once firmware is loaded.**

```bash
./openocd -f tcl/interface/cmsis-dap.cfg -f tcl/target/max78000.cfg -c "program build/MAX78000.elf verify reset exit"
```

### Demo application:

#### Prerequisites:
- Python 3.7 or higher (tested for 3.7.7 and 3.8.1)
- NumPy (>1.18)
- Scipy (1.4)
- PyQt5 (>5.9)
- OpenCv (>3.4)
- PySerial (>3.4)
- MatplotLib (>3.2)
- PyTorch (>1.3.1)
- Torchvision (>0.5.0)

#### Run Demo App 

Navigate to directory 'demo' and run the 'run_demo.py' script:

```bash
$ cd /Examples/MAX78000/CNN/faceid_demo/demo
$ python run_demo.py -c <COM_PORT>
```

When the demo window is open, it is possible to load images from disk or capture images from PC camera. Currently the app db includes images for 5 female and 5 male celebrities.

## CNN Model Design
### Problem Definition
To identify people from 3 channel (RGB) frontal facial images, i.e. portraits. Small amount of rotations should be considered to have a robust application.

### Approach
The main approach in the literature is composed of three steps:

- Face Extraction: Detection of the faces in the image and extract a rectangular subimage that contains only face.
- Face Alignment: The rotation angles (in 3D) of the face in the image is find to compensate its effect by affine transformation.
- Face Identification: The extracted subimage is used to identify the person.

In this project, the aim is to run all those steps in a single AI-85 chip so the approach is to identify the faces with a single from uncropped portraits, each contains 1 face only.

Then, the embeddings (Face ID) are created by FaceNet [2] model as seen below and used these embeddings as our target. There is no need to deal with center loss, triplet loss etc, since those are assumed to be covered by FaceNet model. The loss used in the model development will be Mean Square Error (MSE) between the target and predicted embeddings.

### CNN Model
The CNN model synthesized for MAX78000 is 9 layer sequential model as seen below. It takes 160x120 RGB image from the input and gives out 512 length embedding corresponds to the image.

```python
class AI85FaceIDNet(nn.Module):
    """
    Simple FaceNet Model
    """
    def __init__(
            self,
            num_classes=None, 
            num_channels=3,
            dimensions=(160, 120),
            bias=True,
    ):
        super(AI85FaceIDNet, self).__init__()

        self.conv1 = ai8x.FusedConv2dReLU(num_channels, 16, 3, padding=1,
                                          bias=False)
        self.conv2 = ai8x.FusedMaxPoolConv2dReLU(16, 32, 3, pool_size=2, pool_stride=2,
                                                 padding=1, bias=False)
        self.conv3 = ai8x.FusedMaxPoolConv2dReLU(32, 32, 3, pool_size=2, pool_stride=2,
                                                 padding=1, bias=bias)
        self.conv4 = ai8x.FusedMaxPoolConv2dReLU(32, 64, 3, pool_size=2, pool_stride=2,
                                                 padding=1, bias=bias)
        self.conv5 = ai8x.FusedMaxPoolConv2dReLU(64, 64, 3, pool_size=2, pool_stride=2,
                                                 padding=1, bias=bias)
        self.conv6 = ai8x.FusedConv2dReLU(64, 64, 3, padding=1, bias=bias)
        self.conv7 = ai8x.FusedConv2dReLU(64, 64, 3, padding=1, bias=bias)
        self.conv8 = ai8x.FusedMaxPoolConv2d(64, 512, 1, pool_size=2, pool_stride=2,
                                             padding=0, bias=False)
        self.avgpool = ai8x.AvgPool2d((5, 3))

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.conv5(x)
        x = self.conv6(x)
        x = self.conv7(x)
        x = self.conv8(x)
        x = self.avgpool(x)
        return x
```


## References
[1] MTCNN: https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf

[2] FaceNet: https://arxiv.org/pdf/1503.03832.pdf